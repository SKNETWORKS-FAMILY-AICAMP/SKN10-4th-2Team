import os
import requests
from dotenv import load_dotenv
from .answer_llm import llm_answer

load_dotenv()
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

def tavily_search(user_query: str) -> str:
    """
    Tavily APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì™¸ë¶€ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³ , Gemmaë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±.
    ì§€ì •í•œ ì™€ì¸ ê´€ë ¨ ë„ë©”ì¸ë§Œ ëŒ€ìƒìœ¼ë¡œ ê²€ìƒ‰í•˜ë©°, ì •í™•í•œ ì •ë³´ê°€ ì—†ì„ ê²½ìš°ì—ë„ ë°°ê²½ ì„¤ëª…ì„ ì œê³µí•˜ë„ë¡ ìœ ë„.
    """
    url = "https://api.tavily.com/search"
    headers = {"Content-Type": "application/json"}

    # âœ… ê²€ìƒ‰ ì¿¼ë¦¬ì— site í•„í„° ëª…ì‹œì ìœ¼ë¡œ í¬í•¨
    domain_sites = ["wine21.com", "wine.co.kr", "google.com", "naver.com"]
    filtered_query = f'{user_query} site:' + ' OR site:'.join(domain_sites)

    payload = {
        "api_key": TAVILY_API_KEY,
        "query": filtered_query,
        "search_depth": "advanced",
        "include_answer": False,
        "include_raw_content": True,
        "num_results": 3,
    }

    response = requests.post(url, headers=headers, json=payload)
    response.raise_for_status()
    results = response.json().get("results", [])

    if not results:
        return "ì™¸ë¶€ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤."

    # âœ… ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œ 1ê°œë§Œ ì‚¬ìš©
    top_result = results[0]
    content = top_result.get("content", "")
    source_url = top_result.get("url", "")

    # âœ… í”„ë¡¬í”„íŠ¸: ë°°ê²½ ì„¤ëª… ìœ ë„ + ì „ë¬¸ê°€ ì–´íˆ¬
    prompt = f"""
    ë‹¹ì‹ ì€ ì™€ì¸ ì „ë¬¸ íë ˆì´í„°ì…ë‹ˆë‹¤.

    ë‹¤ìŒì€ ì™¸ë¶€ ì›¹ ë¬¸ì„œì—ì„œ ìˆ˜ì§‘ëœ ì •ë³´ì…ë‹ˆë‹¤.  
    ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ì •í™•í•˜ê³  ì‹ ë¢°ê° ìˆê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

    - ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ì •ë³´ê°€ ë¶€ì¡±í•  ê²½ìš°, ê´€ë ¨ ë°°ê²½ ì§€ì‹ì´ë‚˜ ì¼ë°˜ì ì¸ íŠ¸ë Œë“œë¥¼ ì œì‹œí•´ì£¼ì„¸ìš”.
    - 'ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤'ë¼ëŠ” ë§ì€ í”¼í•˜ê³ , ê°€ëŠ¥í•œ í•œ í’ë¶€í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    - ë°˜ë“œì‹œ ì¹œì ˆí•˜ê³  ì „ë¬¸ê°€ë‹¤ìš´ ì–´íˆ¬ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

    [ì™¸ë¶€ ë¬¸ì„œ ì •ë³´]
    {content}

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {user_query}

    [ì™€ì¸ ì „ë¬¸ê°€ì˜ ë‹µë³€]
    """

    answer = llm_answer(prompt)

    # âœ… ê´€ë ¨ì„± ë†’ì€ ë§í¬ 1ê°œë§Œ í‘œì‹œ
    if source_url:
        answer += f"\n\nğŸ”— ì°¸ê³  ë§í¬: {source_url}"

    return answer
