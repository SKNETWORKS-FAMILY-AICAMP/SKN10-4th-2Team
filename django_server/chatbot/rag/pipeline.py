import subprocess
import re
from .classification import classify_category
from .multiquery import generate_multi_queries
from .relevance_check import is_relevant
from .internal_rag import search_documents, generate_answer_with_docs
from .external_rag import tavily_search

def strip_badge(text: str) -> str:
    """
    ì´ë¯¸ ë¶™ì€ badgeë¥¼ ì œê±°í•˜ëŠ” í›„ì²˜ë¦¬ í•¨ìˆ˜ (ì¤‘ë³µ ì œê±° ë°©ì§€)
    """
    return re.sub(r"<br\s*/?><br\s*/?><span class=['\"]?badge['\"]?>.*?</span>", "", text, flags=re.IGNORECASE)

def sllm_answer(prompt: str, category: str = None, history: list = None) -> str:
    """
    ë¡œì»¬ Ollamaì—ì„œ gemma3-wine:latest ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±.
    ì´ì „ íˆìŠ¤í† ë¦¬ì™€ í•¨ê»˜ ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ì¸ ì™€ì¸ ê´€ë ¨ ì‘ë‹µ ìƒì„±.
    """
    system_prompt = (
        """
        ë‹¹ì‹ ì€ ì™€ì¸ ë¶„ì•¼ì— íŠ¹í™”ëœ ì „ë¬¸ì ì¸ AI íë ˆì´í„°ì…ë‹ˆë‹¤. 
        ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•´ ë‹¤ìŒì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.

        - ë°˜ë“œì‹œ "HTML í˜•ì‹"ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.
        - í•µì‹¬ ìš”ì•½ â†’ ëª©ë¡(`<ul><li>`) â†’ ë³¸ë¬¸ ì„¤ëª… ìˆœìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤.
        - ì¤„ë°”ê¿ˆ(`<br>`)ê³¼ ê°•ì¡°(`<b>`, `<i>`) íƒœê·¸ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.
        - ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ì •ë³´ë§Œ ì¶”ë ¤ì„œ ì‚¬ìš©í•˜ì„¸ìš”.
        - ë‹µì„ ëª¨ë¥¼ ê²½ìš° "ì •í™•í•œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”.
        - "ì €ëŠ” AIì…ë‹ˆë‹¤"ë¼ëŠ” ë¬¸êµ¬ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

        ì˜ˆì‹œ í˜•ì‹:
        ìš”ì•½ ë¬¸ì¥<br>
        <ul>
        <li>í•µì‹¬ í¬ì¸íŠ¸ 1</li>
        <li>í•µì‹¬ í¬ì¸íŠ¸ 2</li>
        </ul>
        <br><br>ë³¸ë¬¸ ì„¤ëª… ë¬¸ë‹¨<br><br>

        ì§ˆë¬¸: {question}
        """
    )

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ìœ ì € ì…ë ¥ì„ í•˜ë‚˜ë¡œ ì—°ê²°
    full_prompt = f"{system_prompt}\n\n{prompt}"

    try:
        # Ollama ëª…ë ¹ì–´ë¡œ subprocess ì‹¤í–‰
        result = subprocess.run(
            ["ollama", "run", "gemma3-wine:latest"],
            input=full_prompt.encode(),  # í”„ë¡¬í”„íŠ¸ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬
            stdout=subprocess.PIPE,      # í‘œì¤€ ì¶œë ¥ì„ ìº¡ì²˜
            stderr=subprocess.PIPE,      # ì˜¤ë¥˜ ì¶œë ¥ì„ ìº¡ì²˜
            timeout=300                    # íƒ€ì„ì•„ì›ƒ ì„¤ì • (300ì´ˆ)
        )
        
        # ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ stderrë¥¼ ì¶œë ¥
        if result.returncode != 0:
            return f"[ì˜¤ë¥˜] Ollama ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr.decode()}"

        # í‘œì¤€ ì¶œë ¥ì—ì„œ ì‘ë‹µ ë‚´ìš© ì¶”ì¶œ
        return result.stdout.decode()

    except Exception as e:
        return f"[ì˜¤ë¥˜] subprocess ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}"




def get_final_answer(user_question: str, history: list) -> str:
    """
    ì „ì²´ ì§ˆë¬¸ íë¦„ì„ ì²˜ë¦¬í•˜ëŠ” ë©”ì¸ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜.
    ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ë¶„ê¸°í•˜ë©°,
    ë‚´ë¶€ ë¬¸ì„œ ê²€ìƒ‰, LLM ì„œë¸Œì§ˆë¬¸, ì™¸ë¶€ ê²€ìƒ‰ ë“±ì„ ë‹¨ê³„ì ìœ¼ë¡œ í™œìš©.
    """
    print(f"[ğŸ’¬] ì§ˆë¬¸: {user_question}")
    category = classify_category(user_question)
    print(f"[ğŸ’¬] ë¶„ë¥˜ëœ ì¹´í…Œê³ ë¦¬: {category}")

    answer = ""
    badge = ""

    if category == "greeting":
        answer = sllm_answer(user_question, category, history)
        badge = "ğŸ§  LLM"

    elif category == "etc":
        temp = sllm_answer(user_question, category, history)
        if is_relevant(user_question, temp):
            answer, badge = temp, "ğŸ§  LLM"
        else:
            docs = search_documents("wine", user_question)
            if docs:
                temp = generate_answer_with_docs(user_question, docs)
                if is_relevant(user_question, temp):
                    answer, badge = temp, "ğŸ“ ë‚´ë¶€ ë¬¸ì„œ"
        if not answer:
            answer = tavily_search(user_question)
            badge = "ğŸŒ ì™¸ë¶€ ë¬¸ì„œ"

    else:  # wine, grape, region, producer
        sub_questions = generate_multi_queries(user_question)
        print(f"[ğŸ’¬] ìƒì„±ëœ ì„œë¸Œ ì§ˆë¬¸ë“¤: {sub_questions}")

        docs = search_documents(category, user_question)
        if docs:
            temp = generate_answer_with_docs(user_question, docs)
            if is_relevant(user_question, temp):
                answer, badge = temp, "ğŸ“ ë‚´ë¶€ ë¬¸ì„œ"

        if not answer:
            for sub_q in sub_questions:
                temp = sllm_answer(sub_q, category, history)
                print(f"[ğŸ’¬] '{sub_q}' â†’ ì‘ë‹µ: {temp[:60]}...")
                if is_relevant(user_question, temp):
                    answer, badge = temp, "ğŸ§  LLM"
                    break

        if not answer:
            answer = tavily_search(user_question)
            badge = "ğŸŒ ì™¸ë¶€ ë¬¸ì„œ"

    cleaned = strip_badge(answer.strip())
    return cleaned + f"<br><br><span class='badge'>{badge}</span>"
